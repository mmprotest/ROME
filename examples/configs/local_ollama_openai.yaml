llm:
  base_url: "http://127.0.0.1:11434/v1"
  api_key: "ollama"
  model: "llama3"
  temperature: 0.2
  max_tokens: 1024
  timeout_s: 120
agent:
  max_steps: 40
  max_turns: 80
  tool_timeout_s: 60
  time_limit_s: 600
  context_max_tokens: 8000
  memory_items: 20
sandbox:
  backend: auto
  network: false
